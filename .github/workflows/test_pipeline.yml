name: Test QCD Pipeline
run-name: ${{ github.actor }} is testing snakemake workflow üöÄ
on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  Test-QCD-Pipeline:
    # runs-on: ubuntu-latest
    runs-on: self-hosted
    steps:
      # - run: echo "üéâ The job was automatically triggered by a ${{ github.event_name }} event."
      # - run: echo "üêß This job is now running on a ${{ runner.os }} server hosted by GitHub!"
      # - run: echo "üîé The name of your branch is ${{ github.ref }} and your repository is ${{ github.repository }}."
      
      - name: Checkout repository
        uses: actions/checkout@v3
      - run: echo "üí° The ${{ github.repository }} repository has been cloned to the runner."
      - run: echo "üñ•Ô∏è The workflow is now ready to test your code on the runner."

      - name: List files in the repository
        run: |
          ls
      # - name: Debug environment
      #   run: |
      #     uname -a
      #     cat /etc/os-release
      #     env
      #     ls /etc/profile.d/
      #     whoami
      #     echo $SHELL

      # - name: SSh into Actions
      #   uses: actions/checkout@v4
      # - name: Setup tmate session
      #   uses: mxschmitt/action-tmate@v3

      - name: Get working directory and load modules
        shell: bash -l {0}
        run: |
          source /etc/profile.d/z11StdEnv.sh
          pwd
          module load Bioinformatics snakemake singularity
          snakemake --version
      
      - name: Running the Pipeline
        run: |
          snakemake -s workflow/QCD.smk -p --use-conda --use-singularity --use-envmodules -j 999 --cluster "sbatch -A {cluster.account} -p {cluster.partition} -N {cluster.nodes}  -t {cluster.walltime} -c {cluster.procs} --mem-per-cpu {cluster.pmem}" --conda-frontend conda --cluster-config .test/config/cluster.json --configfile .test/config/config.yaml --latency-wait 1000 --nolock
          snakemake -s workflow/QCD.smk -p --use-conda --use-singularity --use-envmodules -j 999 --cluster "sbatch -A {cluster.account} -p {cluster.partition} -N {cluster.nodes}  -t {cluster.walltime} -c {cluster.procs} --mem-per-cpu {cluster.pmem}" --conda-frontend conda --cluster-config .test/config/cluster.json --configfile .test/config/config.yaml --latency-wait 1000 --nolock
          snakemake -s workflow/QCD.smk -p --use-conda --use-singularity --use-envmodules -j 999 --cluster "sbatch -A {cluster.account} -p {cluster.partition} -N {cluster.nodes}  -t {cluster.walltime} -c {cluster.procs} --mem-per-cpu {cluster.pmem}" --conda-frontend conda --cluster-config .test/config/cluster.json --configfile .test/config/config.yaml --latency-wait 1000 --nolock
          snakemake -s workflow/QCD_report.smk -p --use-singularity -j 999 --cluster "sbatch -A {cluster.account} -p {cluster.partition} -N {cluster.nodes}  -t {cluster.walltime} -c {cluster.procs} --mem-per-cpu {cluster.pmem}" --conda-frontend conda --cluster-config .test/config/cluster.json --latency-wait 1000 --nolock
      
